\documentclass[a4paper, twocolumn]{article}
\usepackage[pdftex, hidelinks]{hyperref}

\usepackage{bm}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{courier}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{mathtools}
\usepackage{amssymb}
\lstset{basicstyle=\footnotesize\ttfamily,
        breakatwhitespace = false,
        breaklines = true,
        keepspaces = true,
        language = R,
        showspaces = false,
        showstringspaces = false,
        belowcaptionskip = \bigskipamount,
        framerule = 0.80pt,
        frame = tb,
        belowskip = \bigskipamount,
        escapeinside={<@}{@>}}

\title{TDDE01 -- Machine Learning \\
       Group 9 Laboration Report 3}
\author{{Martin Estgren \texttt{<mares480>}} \\
        {Erik S. V. Jansson \texttt{<erija578>}} \\
        {Sebastian Maghsoudi \texttt{<sebma654>}} \\~\\
        {Link√∂ping University (LiU), Sweden}}

\begin{document}
    \pagenumbering{arabic}
    \maketitle % Generate.

    \section*{Assignment 1}

        In this assignment we are tasked with predicting the sex of Australian Crabs given their carapace length and the rear width. For this purpose we will be using
        Linear Discriminant Analyis (LDA) using Maximum Likelihood Estimation for predicting the unknown classification parameters. The first step involves plotting the
        data in order to determine if the data would be linearly separable into different categories (male and female in this case). This plot can be found in below in
        Figure~\ref{fig:crabs}.

        \begin{figure}
          \centering
          \caption{Sex Classification of Australian Crabs}
          \label{fig:crabs}
          \includegraphics[width=0.5\textwidth]{share/crabs.eps}
        \end{figure}

        Our next task is to visualize the decision boundary between the different classifications. Since this is not already implemented by a package in R, we have to
        develop our own LDA method. A LDA can be implemented by comparing Linear Discriminant Functions (LDF) with each other, one for each corresponding class. In practice
        this means, since LDF is implemented with a likelihood function, one can assume that by applying predictor features to the function, the result would yield some indication
        of how likely this observation can be classified as the label corresponding to that LDF. An LDF can be described in the following way:

        \begin{equation} \label{eq:lda}
          \begin{split}
            \delta_k(x) &=  w_1 - b_1 \\
            w_1 &= x^{T}\Sigma^{-1}\mu_k, \\
            b_1 &= \frac{1}{2}\mu_k^{T}\Sigma^{-1}\mu_k+log\pi_k
          \end{split}
        \end{equation}

        After calculating the parameters for both labels (male and female) using the Equation~\ref{eq:lda} above, we can find the intercept and slope of the decision boundary
        separating both of these classes. This is done by simply subtracting each coefficient from each other, thereafter plotting this in Figure~\ref{fig:boundary}. Intuitively this
        is a short method of comparing likelihood of classes given feature predictors.     

        \begin{figure}
          \centering
          \caption{Sex Classification of Australian Crabs}
          \label{fig:boundary}
          \includegraphics[width=0.5\textwidth]{share/boundary.eps}
        \end{figure}
       The final part is to compare the result received by implementing the LDA method with the result from using logistic regression. In r, there is package for this called \textit{glm}. 
	   The function \textit{glm()} returns a vector containing the coefficients including the intersection. The result can be seen in figure \ref{fig:LR}. Ass the observer can see, there 
	   is no significant difference between the result of the method, at least when it come to classify the sample observations. 

    \section*{Assignment 2}
	This assignment revolved around classification of the credit score of clients. The response depended on some other factors commonly linked with what lenders evaluate before giving credit. 
	The credit score of clients could be divided simply in good or bad.\newline
    The methods that is appropriate for this are prediction through a decision tree or a naive Bayesian model. The first model to evaluate is the decision tree. A decision tree simply create  
	model that depending on the value of some attributes can predict the response. The attributes is ranked in a tree form, where the more definitive attributes tend to be at the top. When the 
	the model is used for prediction the algorithm simply traverse the tree and following which path corresponds to the values for the corresponding attribute.

    \nocite{*} % No warnings.
    \bibliographystyle{alpha}
    \bibliography{report}
    \onecolumn \appendix
    \section*{Appendix}

        ...

\end{document}
